{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c50cee3-2c4c-4701-aebf-6b16c962d192",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastai in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (0.10.0+cu111)\n",
      "Requirement already satisfied: pip in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (21.2.4)\n",
      "Requirement already satisfied: torch<1.10,>=1.7.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.9.0+cu111)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (0.24.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (3.3.3)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.7.1)\n",
      "Requirement already satisfied: fastcore<1.4,>=1.3.8 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.3.26)\n",
      "Requirement already satisfied: pillow>6.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (8.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (21.3)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (3.2.4)\n",
      "Requirement already satisfied: pandas in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (1.2.2)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (5.1)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (0.0.5)\n",
      "Requirement already satisfied: requests in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai) (2.25.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.20.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.9.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.6.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.4.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.2)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.0.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (1.0.6)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.7.7)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (8.0.15)\n",
      "Requirement already satisfied: setuptools in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (58.0.4)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<4->fastai) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from packaging->fastai) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4->fastai) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<4->fastai) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (1.26.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->fastai) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pandas->fastai) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai) (2.2.0)\n",
      "Requirement already satisfied: boto3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (1.21.39)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from boto3) (1.0.0)\n",
      "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from boto3) (0.5.2)\n",
      "Requirement already satisfied: botocore<1.25.0,>=1.24.39 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from boto3) (1.24.39)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.39->boto3) (1.26.9)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from botocore<1.25.0,>=1.24.39->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.25.0,>=1.24.39->boto3) (1.16.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from tqdm) (0.4.4)\n",
      "Requirement already satisfied: timm in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.5.4)\n",
      "Requirement already satisfied: torchvision in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from timm) (0.10.0+cu111)\n",
      "Requirement already satisfied: torch>=1.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from timm) (1.9.0+cu111)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torch>=1.4->timm) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision->timm) (1.20.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision->timm) (8.4.0)\n",
      "Requirement already satisfied: wandb in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.12.14)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (8.0.3)\n",
      "Requirement already satisfied: pathtools in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (0.1.2)\n",
      "Requirement already satisfied: protobuf>=3.12.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (3.19.1)\n",
      "Requirement already satisfied: six>=1.13.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.16.0)\n",
      "Requirement already satisfied: shortuuid>=0.5.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.0.8)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (2.25.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (5.1)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.5.9)\n",
      "Requirement already satisfied: promise<3,>=2.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (2.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (5.8.0)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (2.8.2)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (1.2.2)\n",
      "Requirement already satisfied: GitPython>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from wandb) (3.1.27)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from Click!=8.0.0,>=7.0->wandb) (0.4.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.6)\n",
      "Requirement already satisfied: split-folders in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: gdown in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (4.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (3.3.1)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (2.25.1)\n",
      "Requirement already satisfied: six in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (1.16.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (4.10.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from gdown) (4.62.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from beautifulsoup4->gdown) (2.2.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (2021.10.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from tqdm->gdown) (0.4.4)\n",
      "Requirement already satisfied: fastai==2.5.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (2.5.2)\n",
      "Requirement already satisfied: fastcore==1.3.26 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (1.3.26)\n",
      "Requirement already satisfied: pip in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (21.2.4)\n",
      "Requirement already satisfied: torchvision>=0.8.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (0.10.0+cu111)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (5.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (2.25.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (21.3)\n",
      "Requirement already satisfied: fastprogress>=0.2.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.0.2)\n",
      "Requirement already satisfied: spacy<4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (3.2.4)\n",
      "Requirement already satisfied: torch<1.10,>=1.7.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.9.0+cu111)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (3.3.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (0.24.2)\n",
      "Requirement already satisfied: pillow>6.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (8.4.0)\n",
      "Requirement already satisfied: fastdownload<2,>=0.0.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (0.0.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from fastai==2.5.2) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.20.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.0.2)\n",
      "Requirement already satisfied: click<8.1.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (8.0.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (3.0.6)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.7.7)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.6.1)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (8.0.15)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (0.9.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (3.0.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.11.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (4.62.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (58.0.4)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (2.0.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (1.0.6)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from spacy<4->fastai==2.5.2) (3.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from click<8.1.0->spacy<4->fastai==2.5.2) (0.4.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from packaging->fastai==2.5.2) (3.0.4)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pathy>=0.3.5->spacy<4->fastai==2.5.2) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<4->fastai==2.5.2) (3.10.0.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (1.26.9)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (2.6)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from requests->fastai==2.5.2) (2021.10.8)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from jinja2->spacy<4->fastai==2.5.2) (1.1.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai==2.5.2) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai==2.5.2) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from matplotlib->fastai==2.5.2) (2.8.2)\n",
      "Requirement already satisfied: six in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib->fastai==2.5.2) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from pandas->fastai==2.5.2) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai==2.5.2) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from scikit-learn->fastai==2.5.2) (2.2.0)\n",
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Requirement already satisfied: torch==1.9.0+cu111 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (1.9.0+cu111)\n",
      "Requirement already satisfied: torchvision==0.10.0+cu111 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.10.0+cu111)\n",
      "Requirement already satisfied: torchaudio==0.9.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torch==1.9.0+cu111) (3.10.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision==0.10.0+cu111) (1.20.3)\n",
      "Requirement already satisfied: pillow>=5.3.0 in c:\\users\\arrunpersonal\\anaconda3\\lib\\site-packages (from torchvision==0.10.0+cu111) (8.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install fastai\n",
    "!pip install boto3\n",
    "!pip install tqdm\n",
    "!pip install timm\n",
    "!pip install wandb\n",
    "!pip install split-folders\n",
    "!pip install gdown --upgrade\n",
    "!pip install fastai==2.5.2 fastcore==1.3.26\n",
    "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a32e9a81-5777-4035-a8aa-0a813ee14f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cb1bd2a-96d6-4b99-8882-21e6c7297302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import timm\n",
    "#from fastai.distributed import *\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b81e1a-db08-4f87-b8ac-77e17a0e5565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) # Python\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed_value)\n",
    "    if use_cuda: \n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "random_seed(42, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "624c8abd-d9ff-49ae-92f0-825ac681f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cls_module(nf, n_out, lin_ftrs=None, ps=0.5, use_bn=False, first_bn=False, bn_final=False, lin_first=False, y_range=None):\n",
    "    \"Creates classification layer which takes nf flatten features and outputs n_out logits\"\n",
    "    lin_ftrs = [nf, 512, n_out] if lin_ftrs is None else [nf] + lin_ftrs + [n_out]\n",
    "    bns = [first_bn] + [use_bn]*len(lin_ftrs[1:])\n",
    "    ps = L(ps)\n",
    "    if len(ps) == 1: ps = [ps[0]/2] * (len(lin_ftrs)-2) + ps\n",
    "    actns = [nn.ReLU(inplace=True)] * (len(lin_ftrs)-2) + [None]\n",
    "    layers = []\n",
    "    if lin_first: layers.append(nn.Dropout(ps.pop(0)))\n",
    "    for ni,no,bn,p,actn in zip(lin_ftrs[:-1], lin_ftrs[1:], bns, ps, actns):\n",
    "        layers += LinBnDrop(ni, no, bn=bn, p=p, act=actn, lin_first=lin_first)\n",
    "    if lin_first: layers.append(nn.Linear(lin_ftrs[-2], n_out))\n",
    "    if bn_final: layers.append(nn.BatchNorm1d(lin_ftrs[-1], momentum=0.01))\n",
    "    if y_range is not None: layers.append(SigmoidRange(*y_range))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607f559f-ea14-4551-b477-0f6bba93f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'C:/Users/ArrunPersonal/Codes/SceneRecognition Remote Sensing/RSI-CB256_splitted'\n",
    "bs = 16\n",
    "sz = 224\n",
    "\n",
    "data = DataBlock(\n",
    "    blocks=(ImageBlock, CategoryBlock),\n",
    "    get_items=get_image_files,\n",
    "    get_y= parent_label,\n",
    "    splitter= GrandparentSplitter(train_name = \"train\",valid_name = \"val\"))#,\n",
    "    #item_tfms=Resize(460),\n",
    "    #batch_tfms=aug_transforms(mult=1.0, do_flip=True, flip_vert=True, max_rotate=120.0, min_zoom=1.0, max_zoom=1.1, max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75, xtra_tfms=None, size=64, mode='bilinear', pad_mode='reflection', align_corners=True, batch=False, min_scale=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d54d69-5a61-450e-989e-fe0a525dd4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Due to IPython and Windows limitation, python multiprocessing isn't available now.\n",
      "So `number_workers` is changed to 0 to avoid getting stuck\n",
      "Number of classes:  35\n"
     ]
    }
   ],
   "source": [
    "dls = data.dataloaders(path, bs=bs)\n",
    "print(\"Number of classes: \",dls.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036e1f5e-5019-472f-a469-286b7dc9b5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = \"swin_base_patch4_window7_224_in22k\"\n",
    "model = timm.create_model(arch, pretrained=True, in_chans=3, num_classes=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99786deb-5d04-4191-9332-5a2e1dab8db8",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "    (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "  (layers): Sequential(\n",
       "    (0): BasicLayer(\n",
       "      dim=128, input_resolution=(56, 56), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(56, 56), dim=128\n",
       "        (reduction): Linear(in_features=512, out_features=256, bias=False)\n",
       "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicLayer(\n",
       "      dim=256, input_resolution=(28, 28), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(28, 28), dim=256\n",
       "        (reduction): Linear(in_features=1024, out_features=512, bias=False)\n",
       "        (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (2): BasicLayer(\n",
       "      dim=512, input_resolution=(14, 14), depth=18\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (downsample): PatchMerging(\n",
       "        input_resolution=(14, 14), dim=512\n",
       "        (reduction): Linear(in_features=2048, out_features=1024, bias=False)\n",
       "        (norm): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (3): BasicLayer(\n",
       "      dim=1024, input_resolution=(7, 7), depth=2\n",
       "      (blocks): ModuleList(\n",
       "        (0): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlock(\n",
       "          (norm1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): WindowAttention(\n",
       "            (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "            (softmax): Softmax(dim=-1)\n",
       "          )\n",
       "          (drop_path): DropPath()\n",
       "          (norm2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (act): GELU()\n",
       "            (drop1): Dropout(p=0.0, inplace=False)\n",
       "            (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (drop2): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "  (head): Identity()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daf0bff2-3977-4e41-949b-8ceaa89fc771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "410"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict(model.named_modules()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6b45f69-57b0-409c-a310-aae471eb8de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fc = nn.Sequential(create_cls_module(nf=model.num_features, n_out=dls.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbfdf61e-d9eb-4077-9b58-e3a869f34b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "savedfilename = f'{path}_{arch}'\n",
    "learn = Learner(dls, model, metrics=[accuracy,Precision(average='macro'), Recall(average='macro'), F1Score(average='macro')],  cbs=[CSVLogger(fname=savedfilename+'.csv', append=True),\n",
    "                         SaveModelCallback(monitor='valid_loss', comp=None, min_delta=0.0,fname=savedfilename, every_epoch=False, with_opt=False, reset_on_fit=True)])#.to_fp16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93556496-e133-4347-a776-cf60a70c0c98",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ResNet (Input shape: 16)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     16 x 64 x 128 x 128 \n",
       "Conv2d                                    9408       True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "MaxPool2d                                                      \n",
       "Conv2d                                    4096       True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 64 x 64 x 64   \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 64 x 64 x 64   \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    36864      True      \n",
       "BatchNorm2d                               128        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 64 x 64  \n",
       "Conv2d                                    16384      True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 64 x 64  \n",
       "Conv2d                                    32768      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    131072     True      \n",
       "BatchNorm2d                               1024       True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 128 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    147456     True      \n",
       "BatchNorm2d                               256        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 32 x 32  \n",
       "Conv2d                                    65536      True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 32 x 32  \n",
       "Conv2d                                    131072     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    524288     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 256 x 16 x 16  \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    589824     True      \n",
       "BatchNorm2d                               512        True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 1024 x 16 x 16 \n",
       "Conv2d                                    262144     True      \n",
       "BatchNorm2d                               2048       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 16 x 16  \n",
       "Conv2d                                    524288     True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 8 x 8    \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    2097152    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 8 x 8    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 512 x 8 x 8    \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "Conv2d                                    2359296    True      \n",
       "BatchNorm2d                               1024       True      \n",
       "ReLU                                                           \n",
       "____________________________________________________________________________\n",
       "                     16 x 2048 x 8 x 8   \n",
       "Conv2d                                    1048576    True      \n",
       "BatchNorm2d                               4096       True      \n",
       "ReLU                                                           \n",
       "Flatten                                                        \n",
       "AdaptiveAvgPool2d                                              \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     16 x 512            \n",
       "Linear                                    1049088    True      \n",
       "ReLU                                                           \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     16 x 35             \n",
       "Linear                                    17955      True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 24,575,075\n",
       "Total trainable params: 24,575,075\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x0000020AAF4AEF70>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback\n",
       "  - CSVLogger\n",
       "  - SaveModelCallback"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "31c25e71-b8ea-4e10-8a74-0454fd0590b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "SuggestedLRs(valley=0.0004786300996784121)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lr = learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6b8ddd-e365-4d82-8cce-7d01479ffee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fit(20,lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdb5b042-f47d-4e4b-9769-67c394a54b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['swin_base_patch4_window7_224',\n",
       " 'swin_base_patch4_window7_224_in22k',\n",
       " 'swin_base_patch4_window12_384',\n",
       " 'swin_base_patch4_window12_384_in22k',\n",
       " 'swin_large_patch4_window7_224',\n",
       " 'swin_large_patch4_window7_224_in22k',\n",
       " 'swin_large_patch4_window12_384',\n",
       " 'swin_large_patch4_window12_384_in22k',\n",
       " 'swin_small_patch4_window7_224',\n",
       " 'swin_tiny_patch4_window7_224']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"swin*\",pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84bbe389-d2a8-413f-b34b-f55b1d51bf75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['convnext_base',\n",
       " 'convnext_base_384_in22ft1k',\n",
       " 'convnext_base_in22ft1k',\n",
       " 'convnext_base_in22k',\n",
       " 'convnext_large',\n",
       " 'convnext_large_384_in22ft1k',\n",
       " 'convnext_large_in22ft1k',\n",
       " 'convnext_large_in22k',\n",
       " 'convnext_small',\n",
       " 'convnext_tiny',\n",
       " 'convnext_xlarge_384_in22ft1k',\n",
       " 'convnext_xlarge_in22ft1k',\n",
       " 'convnext_xlarge_in22k']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timm.list_models(\"convnext*\",pretrained=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
